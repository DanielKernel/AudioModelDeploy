# ============================================
# Qwen3 Omni API 环境变量配置示例
# ============================================
# 复制此文件为 .env 并根据需要修改配置
# cp env.example .env

# ============================================
# 服务器配置
# ============================================
# 服务器监听地址 (默认: 192.168.1.22)
HOST=192.168.1.22

# 服务器端口 (默认: 9999)
PORT=9999

# ============================================
# 模型配置
# ============================================
# 模型名称或路径 (默认使用Qwen3 Omni模型，如果不存在会自动从ModelScope下载)
MODEL_NAME=Qwen/Qwen3-Omni-30B-A3B-Instruct

# 模型运行设备: cuda, cpu, 或留空自动检测
MODEL_DEVICE=cuda

# PyTorch数据类型: float32, float16, bfloat16, 或留空自动选择
# bfloat16需要在支持Tensor Core的GPU上使用
MODEL_TORCH_DTYPE=bfloat16

# ============================================
# 推理默认参数
# ============================================
# 温度参数 (0.0-2.0, 默认: 0.7)
# 值越大越随机，值越小越确定
DEFAULT_TEMPERATURE=0.7

# Top-p采样参数 (0.0-1.0, 默认: 0.9)
DEFAULT_TOP_P=0.9

# 最大生成token数 (默认: 65535，留空表示不限制)
DEFAULT_MAX_TOKENS=65535

# ============================================
# 日志配置
# ============================================
# 日志级别: DEBUG, INFO, WARNING, ERROR, CRITICAL (默认: INFO)
LOG_LEVEL=INFO

# ============================================
# CORS配置
# ============================================
# 允许的跨域源，多个用逗号分隔 (默认: *)
# 示例: CORS_ORIGINS=http://localhost:3000,https://example.com
CORS_ORIGINS=*

# ============================================
# GPU配置 (DGX/Spark环境)
# ============================================
# GPU数量 (默认: 1)
NUM_GPUS=1

# 可见的GPU设备ID，多个用逗号分隔 (默认: 0)
# 示例: CUDA_VISIBLE_DEVICES=0,1,2,3
CUDA_VISIBLE_DEVICES=0

# ============================================
# 其他配置
# ============================================
# HuggingFace缓存目录 (可选)
# HF_HOME=/path/to/hf_cache

# 模型下载镜像 (可选，用于国内环境)
# HF_ENDPOINT=https://hf-mirror.com
